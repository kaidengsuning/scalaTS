{
  "name": "Scalats",
  "tagline": "Scalable Time Series Analysis on Spark",
  "body": "## Welcome to ScalaTS GitHub Page \r\n###  - First time series analysis enabled to DataFrames in Apache Spark\r\nThe Scalable Time Series (ScalaTS) analysis on Spark aims at building time series analysis for distributed data sets based on Scala/ Java. The utilities and models of ScalaTS are directly implemented with Spark's [DataFrames](http://spark.apache.org/docs/1.5.2/sql-programming-guide.html#dataframe-operations). The ScalaTS serves the Suning's data cloud platform (to be public soon).\r\n\r\nDocs of Updates are published here and the package is hosted at this [GitHub page](http://???).\r\n\r\nThe ScalaTS package keeps enabling time series utilities and models for large-scale time series data sets, as analogous as R's [forecast package](https://cran.r-project.org/web/packages/forecast), Matlab's [time series](http://www.mathworks.com/help/matlab/time-series.html), [Spark-ts](http://sryza.github.io/spark-timeseries/0.3.0/index.html)...\r\n\r\n#### Time Series Utilities\r\n* Time series decomposition\r\n  - It is an important technique for every time series analysis. It aims at decomposing an observed time series into several components including predictable and unpredictable components. Both [additive and multiplicative time series decomposition](https://en.wikipedia.org/wiki/Decomposition_of_time_series) are available.\r\n* Time series lagging\r\n  - Time series lagging generates DataFrames of Spark with lagged terms given an observed time series.\r\n* Time series differencing\r\n  - Time series differencing gives DataFrames of Spark with differenced terms given an observed time series.\r\n* Save or Load models\r\n  - ScalaTS supports functionality of saving and loading time series models.\r\n\r\n#### Time Series Models\r\n* Autocorrelation function\r\n  - The [autocorrelation](https://en.wikipedia.org/wiki/Autocorrelation) reflects the correlation between values of a given time series and at different time lags. It looks for repeating patterns to analyze functions or series of values. For the estimation of a moving average model, the autocorrelation function is applied to determine a proper number of lagged terms (q).\r\n* Partial autocorrelation function (implement both Yule-Walker and OLS methods)\r\n  - With controlling the smaller lags of time series, the [partial autocorrelation function](https://en.wikipedia.org/wiki/Partial_autocorrelation_function) computes the partial correlation with its lagged values. For an autoregressive model, the partial autocorrelation function features identifying the length of lags and deciding an appropriate lags (p).\r\n* AIC/ AICc/ BIC calculations\r\n  - ScalaTS enables calculations of information criterions including Akaike information criterions ([AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion))/ AIC with correction for finite sample sizes ([AICc](https://en.wikipedia.org/wiki/Akaike_information_criterion))/ Bayesian information criterion ([BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion)).\r\n* Autoregressive regression (AR) (implement both Yule-Walker and OLS methods)\r\n  - In statistics and signal process, the [autoregressive model](https://www.otexts.org/fpp/8/3) fits the values of a time series with its own lagged terms and a stochastic term.\r\n* Auto-AR model\r\n  - The auto autoregressive model fits an AR model with a given range of lags (p) according to different information criterions including AIC/ AICc/ BIC. It could automatically choose the best number of lags for AR model.\r\n* Moving average (MA) regression\r\n  - Other than AR model's using lagged terms for a regression, the [moving average model](https://www.otexts.org/fpp/8/4) exploits past forecasting errors in the regression model.\r\n* Auto-MA model\r\n  - The auto moving average model fits an MA model with a given range of values (q) according to different information criterions including AIC/ AICc/ BIC. It could automatically choose the best number of q for MA model.\r\n* Autoregressive moving average (ARMA) regression\r\n  - Given a time series, the [ARMA](https://en.wikipedia.org/wiki/Autoregressive-moving-average_model) plays an important role in understanding and predicting future values in the series. The model combines both AR model and MA model. The AR part fits the values of the series on it own lagged values and the MA part linearly models the error term with the past errors.\r\n* Auto-ARMA model\r\n  - The auto ARMA model finds best order of the autoregressive part (p) and order of the moving average part (q) according to different information criterions including AIC/ AICc/ BIC. It could automatically choose the best number of (p, q) for ARMA model.\r\n* Autoregressive integrated moving average (ARIMA) regression\r\n  - An [ARIMA](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average) model is an generalization of the ARMA model. The difference between ARMA model and ARIMA model is that the time series values in the ARIMA model are replace by the differencing values. And the times of differencing are decided by the order (d).\r\n* Auto-ARIMA model\r\n  - The auto ARIMA model picks best order of the autoregressive part (p), order of the moving average part (q) and order of the integrated part (d) according to different information criterions including AIC/ AICc/ BIC. It could automatically choose the best number of (p, d, q) for ARIMA model.\r\n### Support or Contact\r\nAny questions or comments goes to the [Google group](https://groups.google.com/d/forum/stsas).\r\n\r\nÂ© 2016 Big Data lab, Suning, USA.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}